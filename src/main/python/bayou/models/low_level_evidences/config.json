{
    "model": "lle",
    "latent_size": 64,
    "batch_size": 1,
    "num_epochs": 500,
    "learning_rate": 0.0006,
    "print_step": 500,
    "checkpoint_step": 10,
    "evidence": [
        {
            "name": "apicalls",
            "units": 128,
            "num_layers": 1,
            "tile": 1,
            "max_depth": -1,
            "max_nums": 7
        },
        {
            "name": "types",
            "units": 128,
            "num_layers": 1,
            "tile": 1,
            "max_depth": -1,
            "max_nums": 7
        },
        {
            "name": "keywords",
            "units": 128,
            "num_layers": 1,
            "tile": 1,
            "max_depth": -1,
            "max_nums": 7
        },
        {
            "name": "callsequences",
            "units": 64,
            "num_layers": 1,
            "tile": 1,
            "max_depth": 8,
            "max_nums": 2
        },
        {
            "name": "formalparam",
            "units": 32,
            "num_layers": 1,
            "tile": 1,
            "max_depth": 8,
            "max_nums": 1
        },
        {
            "name": "returntype",
            "units": 16,
            "num_layers": 1,
            "tile": 1,
            "max_depth": -1,
            "max_nums": 1
        },
        {
            "name": "classtype",
            "units": 32,
            "num_layers": 1,
            "tile": 1,
            "max_depth": -1,
            "max_nums": 8
        },
        {
            "name": "sorrreturntype",
            "units": 32,
            "num_layers": 1,
            "tile": 1,
            "max_depth": -1,
            "max_nums": 10
        },
        {
            "name": "sorrformalparam",
            "units": 32,
            "num_layers": 1,
            "tile": 1,
            "max_depth": 8,
            "max_nums": 10
        },
        {
            "name": "sorrcallsequences",
            "units": 64,
            "num_layers": 1,
            "tile": 1,
            "max_depth": 8,
            "max_nums": 10
        }
    ],
    "decoder": {
        "units": 256,
        "num_layers": 1,
        "max_ast_depth": 32
    },
    "reverse_encoder": {
        "units": 256,
        "num_layers": 1,
        "max_ast_depth": 32
    }
}
